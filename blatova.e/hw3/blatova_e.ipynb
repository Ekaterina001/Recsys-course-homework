{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>campaign_clicks</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>oaid_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-27 00:01:30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5664530014561852622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-26 22:54:49.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5186611064559013950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-26 23:57:20.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2215519569292448030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-27 00:04:30.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6262169206735077204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-27 00:06:21.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4778985830203613115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date_time  zone_id  banner_id  campaign_clicks  os_id  \\\n",
       "0  2021-09-27 00:01:30.000000        0          0                0      0   \n",
       "1  2021-09-26 22:54:49.000000        1          1                0      0   \n",
       "2  2021-09-26 23:57:20.000000        2          2                3      0   \n",
       "3  2021-09-27 00:04:30.000000        3          3                0      1   \n",
       "4  2021-09-27 00:06:21.000000        4          4                0      1   \n",
       "\n",
       "   country_id  impressions  clicks            oaid_hash  \n",
       "0           0            1       1  5664530014561852622  \n",
       "1           1            1       1  5186611064559013950  \n",
       "2           0            1       1  2215519569292448030  \n",
       "3           1            1       1  6262169206735077204  \n",
       "4           0            1       1  4778985830203613115  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../../data/data.csv')\n",
    "#let's remove columns we can't use\n",
    "data=data[['date_time', 'zone_id', 'banner_id', 'campaign_clicks',\n",
    "       'os_id', 'country_id', 'impressions', 'clicks', 'oaid_hash']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308174966294367527     5243\n",
       "2890718152668627077    2511\n",
       "2521895603443866206    2289\n",
       "8212556321845734673    1974\n",
       "3375698397737628939    1959\n",
       "                       ... \n",
       "4246377695842597056       1\n",
       "1683601233397340403       1\n",
       "7979441231022932095       1\n",
       "5832726667150953660       1\n",
       "9144315809595125484       1\n",
       "Name: oaid_hash, Length: 6510316, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['oaid_hash'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = data['oaid_hash'].map(data['oaid_hash'].value_counts()) < 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15219867"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остается слишком мало вариантов хешей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['oaid_hash'].map(data['oaid_hash'].value_counts()) < 10 #new users - will change them to id -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11017473"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15821472"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила, что история в 10 кликов - для человека история вполне адекватная, поэтому тут трешхол в 10, а не в 100, как для баннеров. Зато остается адекватное количество разных хешей :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остальной анализ такой же, как и в первой домашке, я не стала переделывать. С анализом там было все в порядке)\n",
    "\n",
    "Кроме oaid_hash все остается таким же, за исключением того, что не делаем dummies - данные потом генерятся отдельно\n",
    "\n",
    "Здесь разрешили не использовать TimeSeriesSplit, чтобы не умереть от старости во время обучения :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    \n",
    "    #let's leave only known banners - that had >100 shows on the train set\n",
    "    train_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==9) & (pd.to_datetime(data['date_time']).dt.day!=1)]\n",
    "    known_banner_ids = set(train_data['banner_id'].value_counts().loc[lambda x: x > 100].index)\n",
    "    data.loc[~data.banner_id.isin(known_banner_ids), 'banner_id']=-1\n",
    "#     data = pd.get_dummies(data, columns = ['banner_id'], drop_first=True, prefix=['banner'])\n",
    "    print(\"Banner columns generated.\")\n",
    "    \n",
    "    data.loc[(data.zone_id>4) & (data.zone_id<10), \"zone_id\"]=-1\n",
    "    data.loc[(data.zone_id>9) & (data.zone_id<20), \"zone_id\"]=-2\n",
    "    data.loc[(data.zone_id>19) & (data.zone_id<50), \"zone_id\"]=-3\n",
    "    data.loc[(data.zone_id>49), \"zone_id\"]=-4\n",
    "    # we could add categoric features here\n",
    "#     data = pd.get_dummies(data, columns = ['zone_id'], drop_first=True, prefix=['zone'])\n",
    "    print(\"Zone columns generated.\")\n",
    "    \n",
    "    #normalize campaign clicks\n",
    "    data.loc[(data.campaign_clicks>50), 'campaign_clicks']=50\n",
    "    data.loc[:,'campaign_clicks']=data['campaign_clicks']/50\n",
    "    \n",
    "    #new users are not very predictable\n",
    "    mask = data['oaid_hash'].map(data['oaid_hash'].value_counts()) < 10\n",
    "    data['oaid_hash']=data['oaid_hash'].mask(mask, -1)\n",
    "\n",
    "    \n",
    "    data.loc[data.os_id>6, \"os_id\"] = 7\n",
    "#     data = pd.get_dummies(data, columns = ['os_id'], drop_first=True, prefix=['os'])\n",
    "    print(\"OS columns generated.\")\n",
    "    \n",
    "#     data = pd.get_dummies(data, columns = ['country_id'], drop_first=True, prefix=['country'])\n",
    "    print(\"Country columns generated.\")\n",
    "    \n",
    "    data = data.drop(columns=['impressions'])\n",
    "    \n",
    "    #we'll use TimeSeries Split this time so no validation dataset\n",
    "    train_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==9) & (pd.to_datetime(data['date_time']).dt.day!=1)]\n",
    "    val_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==10) & (pd.to_datetime(data['date_time']).dt.day==1)]\n",
    "    test_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==10) & (pd.to_datetime(data['date_time']).dt.day==2)]\n",
    "    \n",
    "    train_data = train_data.drop(columns=['date_time'])  \n",
    "    val_data = val_data.drop(columns=['date_time']) \n",
    "    test_data = test_data.drop(columns=['date_time']) \n",
    "    \n",
    "    \n",
    "    return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banner columns generated.\n",
      "Zone columns generated.\n",
      "OS columns generated.\n",
      "Country columns generated.\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз посчитаем бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [column for column in train_data.columns if column!='clicks']\n",
    "train_X = train_data[train_columns]\n",
    "train_y=train_data['clicks']\n",
    "test_X = test_data[train_columns]\n",
    "test_y = test_data['clicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11770857\n",
       "1      278188\n",
       "Name: clicks, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['clicks'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss for mean number of clicks: 1.2226106923947828\n",
      "Log loss for median number of clicks: 1.2226106923947828\n",
      "Log loss for random of clicks: 0.9995558180624815\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log loss for mean number of clicks: {log_loss(test_y, np.full_like(test_y, train_data['clicks'].mean()))}\")\n",
    "print(f\"Log loss for median number of clicks: {log_loss(test_y, np.full_like(test_y, train_data['clicks'].median()))}\")\n",
    "print(f\"Log loss for random of clicks: {log_loss(test_y, np.random.rand(len(test_y)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой домашке получился лог лосс на тесте 0.1434375425967045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем датасеты для train, val и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use anything so copypasted from here: https://github.com/wngaw/blog/blob/master/xlearn_example/src/utils.py\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "def _convert_to_ffm(path, df, type, target, numerics, categories, features, encoder):\n",
    "    # Flagging categorical and numerical fields\n",
    "    print('convert_to_ffm - START')\n",
    "    for x in numerics:\n",
    "        if(x not in encoder['catdict']):\n",
    "            print(f'UPDATING CATDICT: numeric field - {x}')\n",
    "            encoder['catdict'][x] = 0\n",
    "    for x in categories:\n",
    "        if(x not in encoder['catdict']):\n",
    "            print(f'UPDATING CATDICT: categorical field - {x}')\n",
    "            encoder['catdict'][x] = 1\n",
    "\n",
    "    nrows = df.shape[0]\n",
    "    with open(path + str(type) + \"_ffm.txt\", \"w\") as text_file:\n",
    "\n",
    "        # Looping over rows to convert each row to libffm format\n",
    "        for n, r in enumerate(range(nrows)):\n",
    "            datastring = \"\"\n",
    "            datarow = df.iloc[r].to_dict()\n",
    "            datastring += str(int(datarow[target]))  # Set Target Variable here\n",
    "\n",
    "            # For numerical fields, we are creating a dummy field here\n",
    "            for i, x in enumerate(encoder['catdict'].keys()):\n",
    "                if(encoder['catdict'][x] == 0):\n",
    "                    # Not adding numerical values that are nan\n",
    "                    if math.isnan(datarow[x]) is not True:\n",
    "                        datastring = datastring + \" \"+str(i)+\":\" + str(i)+\":\" + str(datarow[x])\n",
    "                else:\n",
    "\n",
    "                    # For a new field appearing in a training example\n",
    "                    if(x not in encoder['catcodes']):\n",
    "#                         print(f'UPDATING CATCODES: categorical field - {x}')\n",
    "                        encoder['catcodes'][x] = {}\n",
    "                        encoder['currentcode'] += 1\n",
    "#                         print(f'UPDATING CATCODES: categorical value for field {x} - {datarow[x]}')\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    # For already encoded fields\n",
    "                    elif(datarow[x] not in encoder['catcodes'][x]):\n",
    "                        encoder['currentcode'] += 1\n",
    "#                         print(f'UPDATING CATCODES: categorical value for field {x} - {datarow[x]}')\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    code = encoder['catcodes'][x][datarow[x]]\n",
    "                    datastring = datastring + \" \"+str(i)+\":\" + str(int(code))+\":1\"\n",
    "\n",
    "            datastring += '\\n'\n",
    "            text_file.write(datastring)\n",
    "    print(\"File written\")\n",
    "\n",
    "    # print('Encoder Summary:')\n",
    "    # print(json.dumps(encoder, indent=4))\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL = 'clicks'\n",
    "NUMERICAL_FEATURES = ['campaign_clicks']\n",
    "CATEGORICAL_FEATURES = [feature for feature in train_columns if feature!='campaign_clicks']\n",
    "ALL_FEATURES = train_columns\n",
    "NUM_THREADS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_ffm - START\n",
      "UPDATING CATDICT: numeric field - campaign_clicks\n",
      "UPDATING CATDICT: categorical field - zone_id\n",
      "UPDATING CATDICT: categorical field - banner_id\n",
      "UPDATING CATDICT: categorical field - os_id\n",
      "UPDATING CATDICT: categorical field - country_id\n",
      "UPDATING CATDICT: categorical field - oaid_hash\n",
      "File written\n",
      "convert_to_ffm - START\n",
      "File written\n",
      "convert_to_ffm - START\n",
      "File written\n"
     ]
    }
   ],
   "source": [
    "#done in previous entries\n",
    "\n",
    "# encoder = {\"currentcode\": len(NUMERICAL_FEATURES),  # Unique index for each numerical field or categorical variables\n",
    "#            \"catdict\": {},  # Dictionary that stores numerical and categorical variables\n",
    "#            \"catcodes\": {}}  # Dictionary that stores index for each categorical variables per categorical field\n",
    "\n",
    "# encoder = _convert_to_ffm('data/', train_data, 'train', GOAL,\n",
    "#                           NUMERICAL_FEATURES,\n",
    "#                           CATEGORICAL_FEATURES,\n",
    "#                           ALL_FEATURES,\n",
    "#                           encoder)\n",
    "\n",
    "# encoder = _convert_to_ffm('data/', val_data, 'val', GOAL,\n",
    "#                           NUMERICAL_FEATURES,\n",
    "#                           CATEGORICAL_FEATURES,\n",
    "#                           ALL_FEATURES,\n",
    "#                           encoder)\n",
    "# encoder = _convert_to_ffm('data/', test_data, 'test', GOAL,\n",
    "#                           NUMERICAL_FEATURES,\n",
    "#                           CATEGORICAL_FEATURES,\n",
    "#                           ALL_FEATURES,\n",
    "#                           encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Временами у меня падает канал, так что, так как данные записаны, буду начинать отсюда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xlearn as xl\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "#https://github.com/aksnzhy/xlearn/blob/master/demo/classification/scikit_learn_demo/example_FFM_criteo.py\n",
    "\n",
    "def cv(dims, lrs, suffix=\"\"):  \n",
    "    best_model = None\n",
    "    best_logloss = 10000\n",
    "    for dim in dims:\n",
    "        for lr in lrs:\n",
    "            ffm_model = xl.create_ffm()\n",
    "            ffm_model.setTrain(\"data/train_ffm.txt\")\n",
    "            ffm_model.setValidate(\"data/val_ffm.txt\")\n",
    "\n",
    "            param = {'task': 'binary',\n",
    "                     'lr': lr,\n",
    "                     'lambda': 0.002, #default value\n",
    "                     'metric': 'auc',\n",
    "                     'k':dim\n",
    "                     }\n",
    "\n",
    "            # Start to train\n",
    "            ffm_model.fit(param, f'trained_models{suffix}/model_lr_{lr}_dim_{dim}.out')\n",
    "\n",
    "            # Cross Validation\n",
    "            ffm_model.cv(param)\n",
    "\n",
    "            # Prediction task\n",
    "            ffm_model.setTest(\"data/val_ffm.txt\")  # Test data\n",
    "            ffm_model.setSigmoid()  # Convert output to 0-1\n",
    "\n",
    "            # Start to predict\n",
    "\n",
    "            ffm_model.predict(f\"trained_models{suffix}/model_lr_{lr}_dim_{dim}.out\", f\"output{suffix}/predictions_lr_{lr}_dim_{dim}.txt\")\n",
    "            y_pred = pd.read_csv(f\"output{suffix}/predictions_lr_{lr}_dim_{dim}.txt\", header=None)\n",
    "            logloss = log_loss(np.array(val_data['clicks']), np.squeeze(np.array(y_pred)))\n",
    "            print(f\"Log loss for model with learning rate {lr} and hidden dim size {dim}: {logloss}\")\n",
    "            if logloss<best_logloss:\n",
    "                best_logloss=logloss\n",
    "                best_model = ffm_model\n",
    "                print(\"This model becomes new best model.\")\n",
    "            print(\"----------\")\n",
    "                \n",
    "    return best_model\n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делать прогон с большим количеством параметров долго\n",
    "# посмотрим, как что заходит\n",
    "\n",
    "dims = [2, 4, 8]\n",
    "lrs = [0.2, 0.1, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss for model with learning rate 0.2 and hidden dim size 2: 0.15690044454616778\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 0.1 and hidden dim size 2: 0.158885377442876\n",
      "----------\n",
      "Log loss for model with learning rate 0.05 and hidden dim size 2: 0.16067262589790215\n",
      "----------\n",
      "Log loss for model with learning rate 0.2 and hidden dim size 4: 0.15673029284902773\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 0.1 and hidden dim size 4: 0.15862258229806955\n",
      "----------\n",
      "Log loss for model with learning rate 0.05 and hidden dim size 4: 0.1605145064051948\n",
      "----------\n",
      "Log loss for model with learning rate 0.2 and hidden dim size 8: 0.15673880696293324\n",
      "----------\n",
      "Log loss for model with learning rate 0.1 and hidden dim size 8: 0.15864537915948765\n",
      "----------\n",
      "Log loss for model with learning rate 0.05 and hidden dim size 8: 0.1605187551877174\n",
      "----------\n",
      "CPU times: user 3h 16min 57s, sys: 37.4 s, total: 3h 17min 35s\n",
      "Wall time: 23min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = cv(dims, lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший лосс был для модели с размерностью 4. Добавим embedding dim 6 и бОльшие lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss for model with learning rate 1.0 and hidden dim size 2: 0.15446655679916366\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 0.5 and hidden dim size 2: 0.15493156943236067\n",
      "----------\n",
      "Log loss for model with learning rate 0.2 and hidden dim size 2: 0.15692496732608574\n",
      "----------\n",
      "Log loss for model with learning rate 0.1 and hidden dim size 2: 0.15878769164945403\n",
      "----------\n",
      "Log loss for model with learning rate 1.0 and hidden dim size 4: 0.15485140138083003\n",
      "----------\n",
      "Log loss for model with learning rate 0.5 and hidden dim size 4: 0.15502533606601304\n",
      "----------\n",
      "Log loss for model with learning rate 0.2 and hidden dim size 4: 0.15708164384069057\n",
      "----------\n",
      "Log loss for model with learning rate 0.1 and hidden dim size 4: 0.15868039296181002\n",
      "----------\n",
      "Log loss for model with learning rate 1.0 and hidden dim size 6: 0.15492777464182358\n",
      "----------\n",
      "Log loss for model with learning rate 0.5 and hidden dim size 6: 0.15547847490532185\n",
      "----------\n",
      "Log loss for model with learning rate 0.2 and hidden dim size 6: 0.15675042259557473\n",
      "----------\n",
      "Log loss for model with learning rate 0.1 and hidden dim size 6: 0.15866295000369215\n",
      "----------\n",
      "Log loss for model with learning rate 1.0 and hidden dim size 8: 0.15458473488994975\n",
      "----------\n",
      "Log loss for model with learning rate 0.5 and hidden dim size 8: 0.15487537925852707\n",
      "----------\n",
      "Log loss for model with learning rate 0.2 and hidden dim size 8: 0.15686927860073918\n",
      "----------\n",
      "Log loss for model with learning rate 0.1 and hidden dim size 8: 0.15882038524901113\n",
      "----------\n",
      "CPU times: user 6h 19min 4s, sys: 1min 28s, total: 6h 20min 32s\n",
      "Wall time: 43min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dims = [2, 4, 6, 8]\n",
    "lrs = [1.0, 0.5, 0.2, 0.1]\n",
    "best_model2 = cv(dims, lrs, suffix=\"_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss for best model on test set is 0.13783525487012696\n"
     ]
    }
   ],
   "source": [
    "best_model2.setTest(\"data/test_ffm.txt\")  # Test data\n",
    "best_model2.setSigmoid()  # Convert output to 0-1\n",
    "\n",
    "# Start to predict\n",
    "\n",
    "best_model2.predict(f\"trained_models_1/model_lr_1.0_dim_2.out\", f\"output_1/best_model_on_test.txt\")\n",
    "y_pred = pd.read_csv(f\"output_1/best_model_on_test.txt\", header=None)\n",
    "logloss = log_loss(np.array(test_data['clicks']), np.squeeze(np.array(y_pred)))\n",
    "\n",
    "print(f\"Log loss for best model on test set is {logloss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Лучший результат на текущий момент:***\n",
    "\n",
    "Validation:\n",
    "Log loss for model with learning rate 1.0 and hidden dim size 2: 0.15446655679916366\n",
    "\n",
    "Test:\n",
    "Log loss for best model on test set is 0.13783525487012696\n",
    "\n",
    "В первой домашке получился лог лосс на тесте 0.1434375425967045 . Мы побили его!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это уже бьет результат для задания 1, но попробуем еще регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xlearn as xl\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "#https://github.com/aksnzhy/xlearn/blob/master/demo/classification/scikit_learn_demo/example_FFM_criteo.py\n",
    "\n",
    "def cv_v2(dims, lrs, lambdas, suffix=\"\"):  \n",
    "    best_model = None\n",
    "    best_logloss = 10000\n",
    "    for dim in dims:\n",
    "        for lr in lrs:\n",
    "            for lambdaa in lambdas:\n",
    "                ffm_model = xl.create_ffm()\n",
    "                ffm_model.setTrain(\"data/train_ffm.txt\")\n",
    "                ffm_model.setValidate(\"data/val_ffm.txt\")\n",
    "\n",
    "                param = {'task': 'binary',\n",
    "                         'lr': lr,\n",
    "                         'lambda': lambdaa,\n",
    "                         'metric': 'auc',\n",
    "                         'k':dim\n",
    "                         }\n",
    "\n",
    "                # Start to train\n",
    "                ffm_model.fit(param, f'trained_models{suffix}/model_lr_{lr}_dim_{dim}_lambda_{lambdaa}.out')\n",
    "\n",
    "                # Cross Validation\n",
    "                ffm_model.cv(param)\n",
    "\n",
    "                # Prediction task\n",
    "                ffm_model.setTest(\"data/val_ffm.txt\")  # Test data\n",
    "                ffm_model.setSigmoid()  # Convert output to 0-1\n",
    "\n",
    "                # Start to predict\n",
    "\n",
    "                ffm_model.predict(f\"trained_models{suffix}/model_lr_{lr}_dim_{dim}_lambda_{lambdaa}.out\", f\"output{suffix}/predictions_lr_{lr}_dim_{dim}_lambda_{lambdaa}.txt\")\n",
    "                y_pred = pd.read_csv(f\"output{suffix}/predictions_lr_{lr}_dim_{dim}_lambda_{lambdaa}.txt\", header=None)\n",
    "                logloss = log_loss(np.array(val_data['clicks']), np.squeeze(np.array(y_pred)))\n",
    "                print(f\"Log loss for model with learning rate {lr}, hidden dim size {dim}, and lambda {lambdaa}: {logloss}\")\n",
    "                if logloss<best_logloss:\n",
    "                    best_logloss=logloss\n",
    "                    best_model = ffm_model\n",
    "                    print(\"This model becomes new best model.\")\n",
    "                print(\"----------\")\n",
    "                \n",
    "    return best_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss for model with learning rate 1.0, hidden dim size 2, and lambda 0.02: 0.1642317308964012\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 2, and lambda 0.002: 0.15617884284396336\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 2, and lambda 0.0002: 0.15190371031951777\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 2, and lambda 2e-05: 0.1517230807683679\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 2, and lambda 0.02: 0.16478820008752781\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 2, and lambda 0.002: 0.1554917996232026\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 2, and lambda 0.0002: 0.1519127724658203\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 2, and lambda 2e-05: 0.15197830386141795\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 2, and lambda 0.02: 0.16695176894439687\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 2, and lambda 0.002: 0.15673696733175663\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 2, and lambda 0.0002: 0.1519073013810601\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 2, and lambda 2e-05: 0.1516903600195684\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 4, and lambda 0.02: 0.16468755733050933\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 4, and lambda 0.002: 0.15474027123132375\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 4, and lambda 0.0002: 0.151435419531236\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 4, and lambda 2e-05: 0.1512194012703924\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 4, and lambda 0.02: 0.16580175932307978\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 4, and lambda 0.002: 0.15521131210111025\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 4, and lambda 0.0002: 0.15158478780264617\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 4, and lambda 2e-05: 0.15206154248012388\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 4, and lambda 0.02: 0.16677582442372033\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 4, and lambda 0.002: 0.15692931702495683\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 4, and lambda 0.0002: 0.1517988369494766\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 4, and lambda 2e-05: 0.1511992556936538\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 6, and lambda 0.02: 0.16518401217741016\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 6, and lambda 0.002: 0.1557812592711972\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 6, and lambda 0.0002: 0.15221460400910553\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 6, and lambda 2e-05: 0.15157196255554542\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 6, and lambda 0.02: 0.16558063359134859\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 6, and lambda 0.002: 0.1555247176319685\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 6, and lambda 0.0002: 0.1522506522158087\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 6, and lambda 2e-05: 0.15114008892927278\n",
      "This model becomes new best model.\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 6, and lambda 0.02: 0.16756396763825185\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 6, and lambda 0.002: 0.15698813500034403\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 6, and lambda 0.0002: 0.15190142199152412\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 6, and lambda 2e-05: 0.15122070756234254\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 8, and lambda 0.02: 0.16438696121267463\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 8, and lambda 0.002: 0.1548322349519562\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 8, and lambda 0.0002: 0.15225451054172298\n",
      "----------\n",
      "Log loss for model with learning rate 1.0, hidden dim size 8, and lambda 2e-05: 0.1516062511497321\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 8, and lambda 0.02: 0.16609305757641682\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 8, and lambda 0.002: 0.15512644527765923\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 8, and lambda 0.0002: 0.1522719682875593\n",
      "----------\n",
      "Log loss for model with learning rate 0.5, hidden dim size 8, and lambda 2e-05: 0.15269719715354368\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 8, and lambda 0.02: 0.1671121014129274\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 8, and lambda 0.002: 0.15679802347709088\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 8, and lambda 0.0002: 0.15209296033730735\n",
      "----------\n",
      "Log loss for model with learning rate 0.2, hidden dim size 8, and lambda 2e-05: 0.15116787572615015\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "dims = [2, 4, 6, 8]\n",
    "lrs = [1.0, 0.5, 0.2]\n",
    "lambdas=[0.02, 0.002, 0.0002, 0.00002]\n",
    "best_model3 = cv_v2(dims, lrs, lambdas, suffix=\"_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss for best model on test set is 0.13751008401444992\n"
     ]
    }
   ],
   "source": [
    "#поресетилось прямо во время исполнения(неправильно написала имя файла). По счастью, все сохраняется\n",
    "best_model3 = xl.create_ffm()\n",
    "best_model3.setTest(\"data/test_ffm.txt\")  # Test data\n",
    "best_model3.setSigmoid()  # Convert output to 0-1\n",
    "\n",
    "# Start to predict\n",
    "\n",
    "best_model3.predict(f\"trained_models_2/model_lr_0.5_dim_6_lambda_2e-05.out\", f\"output_2/best_model_on_test.txt\")\n",
    "y_pred = pd.read_csv(f\"output_2/best_model_on_test.txt\", header=None)\n",
    "logloss = log_loss(np.array(test_data['clicks']), np.squeeze(np.array(y_pred)))\n",
    "\n",
    "print(f\"Log loss for best model on test set is {logloss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Лучший результат-2:***\n",
    "\n",
    "Validation:\n",
    "Log loss for model with learning rate 0.5, hidden dim size 6, and lambda 2e-05: 0.15114008892927278\n",
    "\n",
    "Test:\n",
    "Log loss for best model on test set is 0.13751008401444992\n",
    "\n",
    "В первой домашке получился лог лосс на тесте 0.1434375425967045 . Мы побили его!\n",
    "\n",
    "Предыдущий результат(без подбора lambda): 0.13783525487012696\n",
    "\n",
    "Значение стало лучше, но не сильно. В идеале можно было бы попробовать lambda = 1e-6, но это долго, и непонятно, стоит ли того :) Принцип, в общем-то, понятен :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрику тоже смотреть уже не буду - все и так работало очень долго (прогон последнего Grid Search - около трех часов), и ее не было в задании :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
