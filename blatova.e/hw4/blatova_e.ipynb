{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9bcbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58bfacf",
   "metadata": {},
   "source": [
    "#### Повторим результат для первой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac3a8d",
   "metadata": {},
   "source": [
    "Буду делать все ровно так же. Единственное, выкинем не сыгравшие баннеры и campaign clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526bab53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>oaid_hash</th>\n",
       "      <th>campaign_clicks</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>banner_id0</th>\n",
       "      <th>rate0</th>\n",
       "      <th>g0</th>\n",
       "      <th>coeff_sum0</th>\n",
       "      <th>banner_id1</th>\n",
       "      <th>rate1</th>\n",
       "      <th>g1</th>\n",
       "      <th>coeff_sum1</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-27 00:01:30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5664530014561852622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>-7.268846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>-5.369901</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-26 22:54:49.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5186611064559013950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>-2.657477</td>\n",
       "      <td>269</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>-4.449220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-26 23:57:20.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2215519569292448030</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>-3.824875</td>\n",
       "      <td>21</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>-3.939309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-27 00:04:30.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6262169206735077204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>-3.461357</td>\n",
       "      <td>99</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.050671</td>\n",
       "      <td>-3.418403</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-27 00:06:21.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4778985830203613115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.051265</td>\n",
       "      <td>-4.009026</td>\n",
       "      <td>11464230</td>\n",
       "      <td>6.790</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>-2.828797</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date_time  zone_id  banner_id            oaid_hash  \\\n",
       "0  2021-09-27 00:01:30.000000        0          0  5664530014561852622   \n",
       "1  2021-09-26 22:54:49.000000        1          1  5186611064559013950   \n",
       "2  2021-09-26 23:57:20.000000        2          2  2215519569292448030   \n",
       "3  2021-09-27 00:04:30.000000        3          3  6262169206735077204   \n",
       "4  2021-09-27 00:06:21.000000        4          4  4778985830203613115   \n",
       "\n",
       "   campaign_clicks  os_id  country_id  banner_id0  rate0        g0  \\\n",
       "0                0      0           0        1240  0.067  0.035016   \n",
       "1                0      0           1           1  0.002  0.054298   \n",
       "2                3      0           0           2  0.014  0.014096   \n",
       "3                0      1           1           3  0.012  0.015232   \n",
       "4                0      1           0           4  0.019  0.051265   \n",
       "\n",
       "   coeff_sum0  banner_id1  rate1        g1  coeff_sum1  impressions  clicks  \n",
       "0   -7.268846           0  0.010  0.049516   -5.369901            1       1  \n",
       "1   -2.657477         269  0.004  0.031942   -4.449220            1       1  \n",
       "2   -3.824875          21  0.014  0.014906   -3.939309            1       1  \n",
       "3   -3.461357          99  0.006  0.050671   -3.418403            1       1  \n",
       "4   -4.009026    11464230  6.790  0.032005   -2.828797            1       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "#let's remove columns we can't use\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9aa4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15821472\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48859b0",
   "metadata": {},
   "source": [
    "Выкинем не сыгравшие баннеры и оставим только нужные колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14773063",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['banner_id0']==data['banner_id']]\n",
    "data=data[['date_time', 'zone_id', 'banner_id',\n",
    "       'os_id', 'country_id', 'impressions', 'clicks', 'coeff_sum0', 'g0', 'coeff_sum1', 'g1', 'banner_id1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a538d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a1c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13947160\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37c5a5",
   "metadata": {},
   "source": [
    "Практически все осталось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca8b5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>coeff_sum0</th>\n",
       "      <th>g0</th>\n",
       "      <th>coeff_sum1</th>\n",
       "      <th>g1</th>\n",
       "      <th>banner_id1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-26 22:54:49.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.657477</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>-4.449220</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-26 23:57:20.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.824875</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>-3.939309</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-27 00:04:30.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.461357</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>-3.418403</td>\n",
       "      <td>0.050671</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-27 00:06:21.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.009026</td>\n",
       "      <td>0.051265</td>\n",
       "      <td>-2.828797</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>11464230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-09-27 00:06:50.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.222757</td>\n",
       "      <td>0.337634</td>\n",
       "      <td>-3.221755</td>\n",
       "      <td>0.338195</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date_time  zone_id  banner_id  os_id  country_id  \\\n",
       "1  2021-09-26 22:54:49.000000        1          1      0           1   \n",
       "2  2021-09-26 23:57:20.000000        2          2      0           0   \n",
       "3  2021-09-27 00:04:30.000000        3          3      1           1   \n",
       "4  2021-09-27 00:06:21.000000        4          4      1           0   \n",
       "5  2021-09-27 00:06:50.000000        5          5      2           2   \n",
       "\n",
       "   impressions  clicks  coeff_sum0        g0  coeff_sum1        g1  banner_id1  \n",
       "1            1       1   -2.657477  0.054298   -4.449220  0.031942         269  \n",
       "2            1       1   -3.824875  0.014096   -3.939309  0.014906          21  \n",
       "3            1       1   -3.461357  0.015232   -3.418403  0.050671          99  \n",
       "4            1       1   -4.009026  0.051265   -2.828797  0.032005    11464230  \n",
       "5            1       1   -3.222757  0.337634   -3.221755  0.338195          37  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4af95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    \n",
    "    #let's leave only known banners - that had >100 shows on the train set\n",
    "    train_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==9) & (pd.to_datetime(data['date_time']).dt.day!=1)]\n",
    "    known_banner_ids = set(train_data['banner_id'].value_counts().loc[lambda x: x > 100].index)\n",
    "    data.loc[~data.banner_id.isin(known_banner_ids), 'banner_id']=-1\n",
    "    data = pd.get_dummies(data, columns = ['banner_id'], drop_first=True, prefix=['banner'])\n",
    "    print(\"Banner columns generated.\")\n",
    "    \n",
    "    data.loc[(data.zone_id>4) & (data.zone_id<10), \"zone_id\"]=-1\n",
    "    data.loc[(data.zone_id>9) & (data.zone_id<20), \"zone_id\"]=-2\n",
    "    data.loc[(data.zone_id>19) & (data.zone_id<50), \"zone_id\"]=-3\n",
    "    data.loc[(data.zone_id>49), \"zone_id\"]=-4\n",
    "    data = pd.get_dummies(data, columns = ['zone_id'], drop_first=True, prefix=['zone'])\n",
    "    print(\"Zone columns generated.\")\n",
    "    \n",
    "#     #normalize campaign clicks\n",
    "#     data.loc[(data.campaign_clicks>50), 'campaign_clicks']=50\n",
    "#     data.loc[:,'campaign_clicks']=data['campaign_clicks']/50\n",
    "\n",
    "    \n",
    "    data.loc[data.os_id>6, \"os_id\"] = 7\n",
    "    data = pd.get_dummies(data, columns = ['os_id'], drop_first=True, prefix=['os'])\n",
    "    print(\"OS columns generated.\")\n",
    "    \n",
    "    data = pd.get_dummies(data, columns = ['country_id'], drop_first=True, prefix=['country'])\n",
    "    print(\"Country columns generated.\")\n",
    "    \n",
    "#     let's do interactions between country and banner id\n",
    "#     even banner dummies worked for a long time so I decided not to do that\n",
    "#     ban_cols = (ban_col for ban_col in data.columns if 'banner_' in ban_col)\n",
    "#     country_cols = (country_col for country_col in data.columns if 'country_' in country_col)\n",
    "#     for ban_col in ban_cols:\n",
    "#         for country_col in country_cols:\n",
    "#             data[ban_col+country_col]=data[ban_col]*data[country_col]\n",
    "    \n",
    "    data = data.drop(columns=['impressions'])\n",
    "    \n",
    "    train_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==9) & (pd.to_datetime(data['date_time']).dt.day!=1)]\n",
    "    val_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==10) & (pd.to_datetime(data['date_time']).dt.day==1)]\n",
    "    test_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==10) & (pd.to_datetime(data['date_time']).dt.day==2)]\n",
    "    train_data = train_data.drop(columns=['date_time'])  \n",
    "    val_data = val_data.drop(columns=['date_time']) \n",
    "    test_data = test_data.drop(columns=['date_time']) \n",
    "    \n",
    "    \n",
    "    return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56322dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(train_data, val_data, test_data, alphas_list=[0.2, 0.5, 1.0, 2, 5]):\n",
    "    \n",
    "    \n",
    "    #make X and y\n",
    "    train_columns = [column for column in train_data.columns if column!='clicks']\n",
    "    train_X = train_data[train_columns]\n",
    "    val_X = val_data[train_columns]\n",
    "    test_X = test_data[train_columns]\n",
    "    train_y = train_data['clicks']\n",
    "    val_y = val_data['clicks']\n",
    "    test_y = test_data['clicks']\n",
    "    \n",
    "    \n",
    "    models_list=[]\n",
    "    val_loss_list=[]\n",
    "    best_model=None\n",
    "    best_loss=100000\n",
    "    best_alpha=-1\n",
    "    \n",
    "    #kinda grid search for the best regression coefficient\n",
    "    for alpha in alphas_list:\n",
    "        #as it was discussed during the lecture, the most correct from bayesian point of view is a model with L2 regularization\n",
    "        curr_model = Ridge(alpha=alpha)\n",
    "        curr_model.fit(train_X, train_y)\n",
    "        val_y =curr_model.predict(val_X)\n",
    "        logloss = log_loss(val_data['clicks'], val_y)\n",
    "        models_list.append(curr_model)\n",
    "        val_loss_list.append(logloss)\n",
    "        \n",
    "        print(f\"For alpha {alpha} log loss on validation is {logloss}\")\n",
    "        if logloss<best_loss:\n",
    "            best_loss=logloss\n",
    "            best_alpha=alpha\n",
    "            best_model=curr_model\n",
    "            \n",
    "    #print data for the best model     \n",
    "    test_y = best_model.predict(test_X)\n",
    "    test_logloss = log_loss(test_data['clicks'], test_y)\n",
    "    print(f\"Best validation log loss is {best_loss} for alpha {best_alpha}. Log loss on test data for this model is {test_logloss}\")\n",
    "    return best_model, models_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04e75623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banner columns generated.\n",
      "Zone columns generated.\n",
      "OS columns generated.\n",
      "Country columns generated.\n",
      "CPU times: user 7min 10s, sys: 4min 1s, total: 11min 12s\n",
      "Wall time: 12min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, val_data, test_data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d923d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_prediction=[column for column in train_data.columns if (not 'coeff_sum' in column)and(not 'g0'==column) and (not 'g1'==column) and (not 'banner_id1'==column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f68f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha 0.2 log loss on validation is 0.16239503519611978\n",
      "For alpha 0.5 log loss on validation is 0.16238854681434864\n",
      "For alpha 1.0 log loss on validation is 0.16237944573364246\n",
      "For alpha 2 log loss on validation is 0.1623652208281624\n",
      "For alpha 5 log loss on validation is 0.1623388519787048\n",
      "Best validation log loss is 0.1623388519787048 for alpha 5. Log loss on test data for this model is 0.14497883957185315\n"
     ]
    }
   ],
   "source": [
    "alphas_list= [0.2, 0.5, 1.0, 2, 5]\n",
    "best_model, models_list, val_lost_list = cv(train_data[columns_for_prediction], val_data[columns_for_prediction], test_data[columns_for_prediction], alphas_list = alphas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56936d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4bff56",
   "metadata": {},
   "source": [
    "Тут запустила генерацию данных заново после нескольких попыток их изменения, чтобы быть точно уверенной, что все правильно работает при последовательном исполнении. Модели не трогала, так что их перезапускать не стала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f734d805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banner columns generated.\n",
      "Zone columns generated.\n",
      "OS columns generated.\n",
      "Country columns generated.\n",
      "CPU times: user 7min 4s, sys: 4min 31s, total: 11min 36s\n",
      "Wall time: 12min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, val_data, test_data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "fedaf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = test_data.copy()\n",
    "test_data1 = test_data1[[column for column in test_data1.columns if 'banner_' not in column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a6bc0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1['banner_id']=test_data['banner_id1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744adf35",
   "metadata": {},
   "source": [
    "С one-hot для второго баннера придется пошаманить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e1ec7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.loc[(pd.to_datetime(data['date_time']).dt.month==9) & (pd.to_datetime(data['date_time']).dt.day!=1)]\n",
    "known_banner_ids = set(train_data['banner_id'].value_counts().loc[lambda x: x > 100].index)\n",
    "test_data1.loc[~test_data1.banner_id.isin(known_banner_ids), 'banner_id']=-1\n",
    "test_data1 = pd.get_dummies(test_data1, columns = ['banner_id'], drop_first=True, prefix=['banner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "284b0f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "584\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data.columns))\n",
    "print(len(test_data1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bc29d399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1890488\n",
       "1         74\n",
       "Name: banner_1178, dtype: int64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data1['banner_1178'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "80cf3d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "empty_columns = [column for column in test_data.columns if (('banner_' in column)and('banner_id' not in column) and (column not in test_data1.columns))]\n",
    "print(len(empty_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5d6e826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in empty_columns:\n",
    "    test_data1[col]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6d8323d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "1002\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data.columns))\n",
    "print(len(test_data1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "76743b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1890488\n",
       "1         74\n",
       "Name: banner_1178, dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data1['banner_1178'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9261e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3f24b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data1 = val_data.copy()\n",
    "val_data1 = val_data1[[column for column in val_data1.columns if 'banner_' not in column]]\n",
    "val_data1['banner_id']=val_data['banner_id1']\n",
    "val_data1.loc[~val_data1.banner_id.isin(known_banner_ids), 'banner_id']=-1\n",
    "val_data1 = pd.get_dummies(val_data1, columns = ['banner_id'], drop_first=True, prefix=['banner'])\n",
    "empty_columns = [column for column in val_data.columns if (('banner_' in column)and('banner_id' not in column) and (column not in val_data1.columns))]\n",
    "for col in empty_columns:\n",
    "    val_data1[col]=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f4eda",
   "metadata": {},
   "source": [
    "Недостающая колонка - banner_id1, которую мы не копировали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "764add0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "1002\n"
     ]
    }
   ],
   "source": [
    "print(len(val_data.columns))\n",
    "print(len(val_data1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91fd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a21d4921",
   "metadata": {},
   "source": [
    "Наны в колонках, которые используются для подсчета, портили мне CIPS, и я долго не могла понять, почему я исправила несколько багов, а в ней все равно получаются наны (остальные колонки я смотрела в первом задании, а эти - нет) :) Выкинем их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a5850067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g0              0\n",
       "g1            869\n",
       "coeff_sum0      0\n",
       "coeff_sum1    869\n",
       "clicks          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data1[['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8f9ea889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442740"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a6f0a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data1=val_data1.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1fd3d9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g0            0\n",
       "g1            0\n",
       "coeff_sum0    0\n",
       "coeff_sum1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data1[['g0', 'g1', 'coeff_sum0', 'coeff_sum1']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "497b41a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1441871"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c178d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data=val_data.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])\n",
    "test_data1=test_data1.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])\n",
    "test_data=test_data.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccec565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc94bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "70821381",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_for_prediction:\n",
    "    if column not in val_data1.columns:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "2f6f7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_prediction2 = [column for column in columns_for_prediction if (column!='clicks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f01d4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_first_sampling_is_greater_than_second(mu1, sigma1, mu2, sigma2):\n",
    "    mu_diff = mu1-mu2 #mu for dist1-dist2\n",
    "    sigma_diff = np.sqrt(sigma1**2 + sigma2**2)#sigma for dist1 - dist2\n",
    "    #we don't want nans in result\n",
    "    sigma_diff[sigma_diff==0]=1e-7\n",
    "    #that's still the normal distribution\n",
    "    return 1 - stats.norm.cdf(0, mu_diff, sigma_diff) #prob((dist1 - dist2)>0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c7dde140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit\n",
    "\n",
    "def get_coeffs_sum(df, model):\n",
    "    #columns_for_prediction are helping us with a correct columns order\n",
    "    preds = model.predict(df[columns_for_prediction2])\n",
    "    #we don't want logit to be nan\n",
    "    preds[preds>=1]=1 - 1e-7\n",
    "    preds[preds<=0]=1e-7\n",
    "    return logit(preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "77f50d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIPS(pi_0, pi_1, reward, lambdaa=10):\n",
    "    return np.sum(reward*np.minimum(pi_0/pi_1,lambdaa))/(len(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ee303781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CIPS_by_model_on_val(model):\n",
    "    pi_0 = get_prob_first_sampling_is_greater_than_second(val_data['coeff_sum0'].to_numpy(), val_data['g0'].to_numpy(), val_data['coeff_sum1'].to_numpy(), val_data['g1'].to_numpy())\n",
    "    pi_1 = get_prob_first_sampling_is_greater_than_second(get_coeffs_sum(val_data, model), val_data['g0'].to_numpy(), get_coeffs_sum(val_data1, model), val_data['g1'].to_numpy())\n",
    "    pi_1[pi_1==0]=1e-7\n",
    "    return CIPS(pi_0, pi_1, val_data['clicks'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d945f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CIPS_by_model_on_test(model):\n",
    "    \n",
    "    pi_0 = get_prob_first_sampling_is_greater_than_second(test_data['coeff_sum0'], test_data['g0'], test_data['coeff_sum1'], test_data['g1'])\n",
    "    pi_1 = get_prob_first_sampling_is_greater_than_second(get_coeffs_sum(test_data, model), test_data['g0'], get_coeffs_sum(test_data1, model), test_data['g1'])\n",
    "    pi_1[pi_1==0]=1e-7\n",
    "    return CIPS(pi_0, pi_1, test_data['clicks'].to_numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "07941369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042277013685690326\n",
      "0.036045013178339795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(val_data['clicks']))\n",
    "print(np.mean(test_data['clicks']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe81dcd",
   "metadata": {},
   "source": [
    "Посмотрим на CIPS при разных коэффициентах регуляризации\n",
    "\n",
    "CIPS - оценка value (то есть реварда, который мы получим), поэтому ее надо максимизировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2860a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIPS on validation for model with alpha=0.2 is 0.09525745784915227\n",
      "CIPS on validation for model with alpha=0.5 is 0.09519166475509483\n",
      "CIPS on validation for model with alpha=1.0 is 0.09509585505963003\n",
      "CIPS on validation for model with alpha=2 is 0.094874779655249\n",
      "CIPS on validation for model with alpha=5 is 0.09433513158578342\n"
     ]
    }
   ],
   "source": [
    "max_CIPS=-100500\n",
    "best_i=-1\n",
    "\n",
    "for i, model in enumerate(models_list):\n",
    "    curr_CIPS=get_CIPS_by_model_on_val(model)\n",
    "    print(f\"CIPS on validation for model with alpha={alphas_list[i]} is {curr_CIPS}\")\n",
    "    if(curr_CIPS>max_CIPS):\n",
    "        max_CIPS=curr_CIPS\n",
    "        best_i = i\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b34407",
   "metadata": {},
   "source": [
    "CIPS относительно похоже по значению на CTR, но отличается в несколько раз в большую сторону - похоже, все норм\n",
    "\n",
    "Единственное, что меня смущает - что для log loss получается лучший (минимальный) результат при больших alpha, а тут - наоборот. Видимо, издержки того, что результаты для второго баннера мы все-таки не знаем..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "745b63c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model (by CIPS on validation) on test has alpha=0.2. Its CIPS on test is 0.08385523080019004\n"
     ]
    }
   ],
   "source": [
    "CIPS_on_test = get_CIPS_by_model_on_test(models_list[best_i])\n",
    "print(f\"Best model (by CIPS on validation) on test has alpha={alphas_list[best_i]}. Its CIPS on test is {CIPS_on_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55caf88",
   "metadata": {},
   "source": [
    "Попробуем еще уменьшить коэффициент регуляризации. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7adb5",
   "metadata": {},
   "source": [
    "В этом месте пришлось перезапустить кернел, он умер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba654bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banner columns generated.\n",
      "Zone columns generated.\n",
      "OS columns generated.\n",
      "Country columns generated.\n",
      "CPU times: user 6min 45s, sys: 4min 7s, total: 10min 53s\n",
      "Wall time: 11min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, val_data, test_data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b28350e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_prediction=[column for column in train_data.columns if (not 'coeff_sum' in column)and(not 'g0'==column) and (not 'g1'==column) and (not 'banner_id1'==column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dae61e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha 0.2 log loss on validation is 0.16239503519611978\n",
      "For alpha 0.1 log loss on validation is 0.16239744422219654\n",
      "For alpha 0.01 log loss on validation is 0.16239975020899494\n",
      "For alpha 0.001 log loss on validation is 0.16239998901414354\n",
      "For alpha 0.0001 log loss on validation is 0.16240001298289916\n",
      "For alpha 1e-05 log loss on validation is 0.16240001538066393\n",
      "Best validation log loss is 0.16239503519611978 for alpha 0.2. Log loss on test data for this model is 0.1452986518084258\n"
     ]
    }
   ],
   "source": [
    "alphas_list= [0.2, 0.1, 0.01, 0.001, 1e-4, 1e-5]\n",
    "best_model2, models_list2, val_lost_list2 = cv(train_data[columns_for_prediction], val_data[columns_for_prediction], test_data[columns_for_prediction], alphas_list = alphas_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b85be4",
   "metadata": {},
   "source": [
    "Здесь опять генерим данные по баннерам и выкидываем наны для тех колонок, которые нам нужны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f711b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = data.loc[(pd.to_datetime(data['date_time']).dt.month==9) & (pd.to_datetime(data['date_time']).dt.day!=1)]\n",
    "known_banner_ids = set(train_data2['banner_id'].value_counts().loc[lambda x: x > 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d4a6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = test_data.copy()\n",
    "test_data1 = test_data1[[column for column in test_data1.columns if 'banner_' not in column]]\n",
    "test_data1['banner_id']=test_data['banner_id1']\n",
    "test_data1.loc[~test_data1.banner_id.isin(known_banner_ids), 'banner_id']=-1\n",
    "test_data1 = pd.get_dummies(test_data1, columns = ['banner_id'], drop_first=True, prefix=['banner'])\n",
    "empty_columns = [column for column in test_data.columns if (('banner_' in column)and('banner_id' not in column) and (column not in test_data1.columns))]\n",
    "for col in empty_columns:\n",
    "    test_data1[col]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23bbe6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data1 = val_data.copy()\n",
    "val_data1 = val_data1[[column for column in val_data1.columns if 'banner_' not in column]]\n",
    "val_data1['banner_id']=val_data['banner_id1']\n",
    "val_data1.loc[~val_data1.banner_id.isin(known_banner_ids), 'banner_id']=-1\n",
    "val_data1 = pd.get_dummies(val_data1, columns = ['banner_id'], drop_first=True, prefix=['banner'])\n",
    "empty_columns = [column for column in val_data.columns if (('banner_' in column)and('banner_id' not in column) and (column not in val_data1.columns))]\n",
    "for col in empty_columns:\n",
    "    val_data1[col]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eddbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_prediction2 = [column for column in columns_for_prediction if (column!='clicks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de82d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data1=val_data1.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])\n",
    "val_data=val_data.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])\n",
    "test_data1=test_data1.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])\n",
    "test_data=test_data.dropna(subset = ['g0', 'g1', 'coeff_sum0', 'coeff_sum1', 'clicks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e954cf39",
   "metadata": {},
   "source": [
    "Скопировала все функции вместе, чтобы отдельно не перезапускать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a15416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit\n",
    "import numpy as np\n",
    "\n",
    "def get_prob_first_sampling_is_greater_than_second(mu1, sigma1, mu2, sigma2):\n",
    "    mu_diff = mu1-mu2 #mu for dist1-dist2\n",
    "    sigma_diff = np.sqrt(sigma1**2 + sigma2**2)#sigma for dist1 - dist2\n",
    "    #we don't want nans in result\n",
    "    sigma_diff[sigma_diff==0]=1e-7\n",
    "    #that's still the normal distribution\n",
    "    return 1 - stats.norm.cdf(0, mu_diff, sigma_diff) #prob((dist1 - dist2)>0)\n",
    "\n",
    "def get_coeffs_sum(df, model):\n",
    "    #columns_for_prediction are helping us with a correct columns order\n",
    "    preds = model.predict(df[columns_for_prediction2])\n",
    "    #we don't want logit to be nan\n",
    "    preds[preds>=1]=1 - 1e-7\n",
    "    preds[preds<=0]=1e-7\n",
    "    return logit(preds)\n",
    "\n",
    "def CIPS(pi_0, pi_1, reward, lambdaa=10):\n",
    "    return np.sum(reward*np.minimum(pi_0/pi_1,lambdaa))/(len(reward))\n",
    "\n",
    "def get_CIPS_by_model_on_val(model):\n",
    "    pi_0 = get_prob_first_sampling_is_greater_than_second(val_data['coeff_sum0'].to_numpy(), val_data['g0'].to_numpy(), val_data['coeff_sum1'].to_numpy(), val_data['g1'].to_numpy())\n",
    "    pi_1 = get_prob_first_sampling_is_greater_than_second(get_coeffs_sum(val_data, model), val_data['g0'].to_numpy(), get_coeffs_sum(val_data1, model), val_data['g1'].to_numpy())\n",
    "    pi_1[pi_1==0]=1e-7\n",
    "    return CIPS(pi_0, pi_1, val_data['clicks'].to_numpy())\n",
    "\n",
    "def get_CIPS_by_model_on_test(model): \n",
    "    pi_0 = get_prob_first_sampling_is_greater_than_second(test_data['coeff_sum0'], test_data['g0'], test_data['coeff_sum1'], test_data['g1'])\n",
    "    pi_1 = get_prob_first_sampling_is_greater_than_second(get_coeffs_sum(test_data, model), test_data['g0'], get_coeffs_sum(test_data1, model), test_data['g1'])\n",
    "    pi_1[pi_1==0]=1e-7\n",
    "    return CIPS(pi_0, pi_1, test_data['clicks'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f1add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIPS on validation for model with alpha=0.2 is 0.09525745784915227\n",
      "CIPS on validation for model with alpha=0.1 is 0.09528947126236129\n",
      "CIPS on validation for model with alpha=0.01 is 0.09531045635652971\n",
      "CIPS on validation for model with alpha=0.001 is 0.09531322432167641\n",
      "CIPS on validation for model with alpha=0.0001 is 0.09531349737172144\n",
      "CIPS on validation for model with alpha=1e-05 is 0.09531352698238812\n"
     ]
    }
   ],
   "source": [
    "max_CIPS=-100500\n",
    "best_i=-1\n",
    "\n",
    "for i, model in enumerate(models_list2):\n",
    "    curr_CIPS=get_CIPS_by_model_on_val(model)\n",
    "    print(f\"CIPS on validation for model with alpha={alphas_list[i]} is {curr_CIPS}\")\n",
    "    if(curr_CIPS>max_CIPS):\n",
    "        max_CIPS=curr_CIPS\n",
    "        best_i = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02958d",
   "metadata": {},
   "source": [
    "Тут кажется, что чем меньше регуляризация, тем лучше. Но, вообще, совсем чуть-чуть отличается..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8acb56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model (by CIPS on validation) on test has alpha=1e-05. Its CIPS on test is 0.08390874146745823\n"
     ]
    }
   ],
   "source": [
    "CIPS_on_test = get_CIPS_by_model_on_test(models_list2[best_i])\n",
    "print(f\"Best model (by CIPS on validation) on test has alpha={alphas_list[best_i]}. Its CIPS on test is {CIPS_on_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7da17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcab61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed36cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd47b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a541298c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba818669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261d1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7cef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee23eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
